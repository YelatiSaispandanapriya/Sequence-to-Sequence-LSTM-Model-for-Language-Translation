{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PqT5D0Ju4UyC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nhOMPgSB4cqW"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2UQmhvne6zbH"
      },
      "outputs": [],
      "source": [
        "path_to_file = '/content/fra.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ozWrK6kE6v2f"
      },
      "outputs": [],
      "source": [
        "with open(path_to_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().strip().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-f1p20-7BL3",
        "outputId": "79fef17c-8167-4e45-a78b-5233258661df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using last 10000 sentence pairs.\n"
          ]
        }
      ],
      "source": [
        "NUM_SAMPLES = 10000\n",
        "pairs_raw = lines[-NUM_SAMPLES:]\n",
        "print(\"Using last\", NUM_SAMPLES, \"sentence pairs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ns3ZcO7D74",
        "outputId": "44220fd9-1ad9-4743-e6a0-a85272c19bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i m very happy ! ! ! a bientot .\n"
          ]
        }
      ],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    # Normalize accents: \"é\" -> \"e\"\n",
        "    return \"\".join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", s)\n",
        "        if unicodedata.category(c) != \"Mn\"\n",
        "    )\n",
        "\n",
        "def preprocess_sentence(s):\n",
        "    # Lowercase, strip, remove accents\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "\n",
        "    # Put spaces around punctuation we want to keep as tokens\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "\n",
        "    # Remove anything that's not a letter, punctuation or space\n",
        "    s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "\n",
        "    # Collapse multiple spaces\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "    return s\n",
        "\n",
        "# Test the preprocessing\n",
        "print(preprocess_sentence(\"I'm very happy!!! À bientôt.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPxAGdiD7R69",
        "outputId": "0cd9d320-2acf-4943-d71e-34235109d29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "EN: even tom wasn t able to answer the teacher s questions .\n",
            "FR in : <start> meme tom n a pas pu repondre aux questions du professeur .\n",
            "FR out: meme tom n a pas pu repondre aux questions du professeur . <end>\n",
            "---\n",
            "EN: even if it costs , yen , i must buy the dictionary .\n",
            "FR in : <start> je dois acheter ce dictionnaire , meme s il coute . yens .\n",
            "FR out: je dois acheter ce dictionnaire , meme s il coute . yens . <end>\n",
            "---\n",
            "EN: even if she comes to see me , tell her i am not at home .\n",
            "FR in : <start> meme si elle devait passer , dis lui que je ne suis pas a la maison .\n",
            "FR out: meme si elle devait passer , dis lui que je ne suis pas a la maison . <end>\n",
            "---\n",
            "Total cleaned sentence pairs: 10000\n"
          ]
        }
      ],
      "source": [
        "# Building sentence pairs (English, French)\n",
        "#         and add <start> / <end> tokens to French\n",
        "\n",
        "eng_texts = []\n",
        "fra_texts = []          # with <start> and <end>\n",
        "fra_texts_target = []   # target sentences without <start> (for convenience)\n",
        "\n",
        "for line in pairs_raw:\n",
        "    eng, fra, *_ = line.split(\"\\t\")\n",
        "\n",
        "    eng_clean = preprocess_sentence(eng)\n",
        "    fra_clean = preprocess_sentence(fra)\n",
        "\n",
        "    # Add special tokens for target language\n",
        "    fra_in = \"<start> \" + fra_clean\n",
        "    fra_out = fra_clean + \" <end>\"\n",
        "\n",
        "    eng_texts.append(eng_clean)\n",
        "    fra_texts.append(fra_in)\n",
        "    fra_texts_target.append(fra_out)\n",
        "\n",
        "print(\"Examples:\")\n",
        "for i in range(3):\n",
        "    print(f\"EN: {eng_texts[i]}\")\n",
        "    print(f\"FR in : {fra_texts[i]}\")\n",
        "    print(f\"FR out: {fra_texts_target[i]}\")\n",
        "    print(\"---\")\n",
        "\n",
        "num_sentences = len(eng_texts)\n",
        "print(\"Total cleaned sentence pairs:\", num_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB5BBIbo76g9",
        "outputId": "d30ad0af-dcd8-493a-b856-d1f0c6edbd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English vocab size: 7595\n",
            "French vocab size : 10105\n",
            "Max English length: 70\n",
            "Max French length : 74\n"
          ]
        }
      ],
      "source": [
        "# Tokenization and integer sequences\n",
        "\n",
        "# Tokenizer for English\n",
        "eng_tokenizer = Tokenizer(filters=\"\", lower=False)  # data already lowercased\n",
        "eng_tokenizer.fit_on_texts(eng_texts)\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(eng_texts)\n",
        "\n",
        "# Tokenizer for French\n",
        "fra_tokenizer = Tokenizer(filters=\"\", lower=False)\n",
        "fra_tokenizer.fit_on_texts(fra_texts + fra_texts_target)  # include both in/out\n",
        "fra_sequences_in = fra_tokenizer.texts_to_sequences(fra_texts)\n",
        "fra_sequences_out = fra_tokenizer.texts_to_sequences(fra_texts_target)\n",
        "\n",
        "# Vocabulary sizes (+1 for padding index 0)\n",
        "num_encoder_tokens = len(eng_tokenizer.word_index) + 1\n",
        "num_decoder_tokens = len(fra_tokenizer.word_index) + 1\n",
        "\n",
        "print(\"English vocab size:\", num_encoder_tokens)\n",
        "print(\"French vocab size :\", num_decoder_tokens)\n",
        "\n",
        "# Find max sequence lengths\n",
        "max_len_eng = max(len(seq) for seq in eng_sequences)\n",
        "max_len_fra = max(len(seq) for seq in fra_sequences_in)\n",
        "\n",
        "print(\"Max English length:\", max_len_eng)\n",
        "print(\"Max French length :\", max_len_fra)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX3ZN9sj8GIo",
        "outputId": "6078a3d6-f7c9-483c-e02c-2eb48bf7debe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_data shape: (10000, 70)\n",
            "decoder_input_data shape: (10000, 74)\n",
            "decoder_target_data shape: (10000, 74)\n",
            "Training samples: 8000\n",
            "Test samples     : 2000\n",
            "decoder_target_train shape (for sparse loss): (8000, 74, 1)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 6: Padding and train-test split (80/20)\n",
        "# ============================================================\n",
        "\n",
        "# Pad sequences\n",
        "encoder_input_data = pad_sequences(eng_sequences, maxlen=max_len_eng, padding=\"post\")\n",
        "decoder_input_data = pad_sequences(fra_sequences_in, maxlen=max_len_fra, padding=\"post\")\n",
        "decoder_target_data = pad_sequences(fra_sequences_out, maxlen=max_len_fra, padding=\"post\")\n",
        "\n",
        "print(\"encoder_input_data shape:\", encoder_input_data.shape)\n",
        "print(\"decoder_input_data shape:\", decoder_input_data.shape)\n",
        "print(\"decoder_target_data shape:\", decoder_target_data.shape)\n",
        "\n",
        "# Train/test split: first 80% train, last 20% test\n",
        "train_size = int(0.8 * num_sentences)\n",
        "\n",
        "encoder_input_train = encoder_input_data[:train_size]\n",
        "decoder_input_train = decoder_input_data[:train_size]\n",
        "decoder_target_train = decoder_target_data[:train_size]\n",
        "\n",
        "encoder_input_test = encoder_input_data[train_size:]\n",
        "decoder_input_test = decoder_input_data[train_size:]\n",
        "decoder_target_test = decoder_target_data[train_size:]\n",
        "\n",
        "print(\"Training samples:\", encoder_input_train.shape[0])\n",
        "print(\"Test samples     :\", encoder_input_test.shape[0])\n",
        "\n",
        "# For sparse_categorical_crossentropy, we need an extra dimension for targets\n",
        "decoder_target_train = np.expand_dims(decoder_target_train, -1)\n",
        "decoder_target_test = np.expand_dims(decoder_target_test, -1)\n",
        "print(\"decoder_target_train shape (for sparse loss):\", decoder_target_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvpfRy7l8NQH",
        "outputId": "a7996ed4-2b0d-4505-aac2-62c86b065434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example decoded English sentence from padded indices:\n",
            "even tom wasn t able to answer the teacher s questions .\n"
          ]
        }
      ],
      "source": [
        "# Helper dictionaries for word <-> index mapping\n",
        "\n",
        "eng_index_to_word = {idx: w for w, idx in eng_tokenizer.word_index.items()}\n",
        "fra_index_to_word = {idx: w for w, idx in fra_tokenizer.word_index.items()}\n",
        "\n",
        "def decode_sequence_indices(indices, idx_to_word):\n",
        "    words = []\n",
        "    for idx in indices:\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        word = idx_to_word.get(idx, \"\")\n",
        "        if word == \"<end>\":\n",
        "            break\n",
        "        words.append(word)\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(\"Example decoded English sentence from padded indices:\")\n",
        "print(decode_sequence_indices(encoder_input_data[0], eng_index_to_word))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "vD0qqaHw8QGr",
        "outputId": "c9221bca-cab3-415c-879d-f0f3a80482eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,944,320</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,586,880</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ decoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10105</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,303,545</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,944,320\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,586,880\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │    \u001b[38;5;34m197,120\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m128\u001b[0m), │    \u001b[38;5;34m197,120\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m10105\u001b[0m) │  \u001b[38;5;34m1,303,545\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,228,985</span> (23.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,228,985\u001b[0m (23.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,228,985</span> (23.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,228,985\u001b[0m (23.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to build Seq2Seq model (Encoder-Decoder)\n",
        "\n",
        "def build_seq2seq_model(latent_dim, embedding_dim=256):\n",
        "    \"\"\"\n",
        "    Build a standard Encoder-Decoder LSTM model with given latent_dim.\n",
        "    Returns:\n",
        "        model, encoder_inputs, encoder_states,\n",
        "        decoder_inputs, decoder_lstm, decoder_dense, decoder_embedding\n",
        "    \"\"\"\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_len_eng,), name=\"encoder_inputs\")\n",
        "    encoder_embedding = Embedding(\n",
        "        input_dim=num_encoder_tokens,\n",
        "        output_dim=embedding_dim,\n",
        "        mask_zero=True,\n",
        "        name=\"encoder_embedding\",\n",
        "    )(encoder_inputs)\n",
        "    encoder_lstm = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_len_fra,), name=\"decoder_inputs\")\n",
        "    decoder_embedding_layer = Embedding(\n",
        "        input_dim=num_decoder_tokens,\n",
        "        output_dim=embedding_dim,\n",
        "        mask_zero=True,\n",
        "        name=\"decoder_embedding\",\n",
        "    )\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "    decoder_lstm = LSTM(\n",
        "        latent_dim,\n",
        "        return_sequences=True,\n",
        "        return_state=True,\n",
        "        name=\"decoder_lstm\",\n",
        "    )\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\", name=\"decoder_dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(\n",
        "        optimizer=\"rmsprop\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        model,\n",
        "        encoder_inputs,\n",
        "        encoder_states,\n",
        "        decoder_inputs,\n",
        "        decoder_lstm,\n",
        "        decoder_dense,\n",
        "        decoder_embedding_layer,\n",
        "    )\n",
        "\n",
        "# Quick sanity check\n",
        "test_model, *_ = build_seq2seq_model(latent_dim=128)\n",
        "test_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Gk0RdV0r8V3t"
      },
      "outputs": [],
      "source": [
        "# Build inference models (encoder_model, decoder_model)\n",
        "\n",
        "def build_inference_models(\n",
        "    encoder_inputs,\n",
        "    encoder_states,\n",
        "    decoder_inputs,\n",
        "    decoder_lstm,\n",
        "    decoder_dense,\n",
        "    decoder_embedding_layer,\n",
        "    latent_dim,\n",
        "):\n",
        "    # Encoder model for inference\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Decoder setup for inference\n",
        "    # We need new input tensors for hidden states\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,), name=\"decoder_state_input_h\")\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,), name=\"decoder_state_input_c\")\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # Decoder input (one token at a time)\n",
        "    decoder_single_input = Input(shape=(1,), name=\"decoder_single_input\")\n",
        "    dec_emb2 = decoder_embedding_layer(decoder_single_input)\n",
        "\n",
        "    decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
        "        dec_emb2, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "    decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "    decoder_model = Model(\n",
        "        [decoder_single_input] + decoder_states_inputs,\n",
        "        [decoder_outputs2] + decoder_states2,\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RjoHHCGe8ZEZ"
      },
      "outputs": [],
      "source": [
        "# Decoding function (greedy search)\n",
        "\n",
        "start_token = fra_tokenizer.word_index[\"<start>\"]\n",
        "end_token = fra_tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "def decode_sequence_greedy(input_seq, encoder_model, decoder_model, max_target_len=None):\n",
        "    if max_target_len is None:\n",
        "        max_target_len = max_len_fra\n",
        "\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    target_seq = np.array([[start_token]], dtype=\"int32\")\n",
        "    decoded_tokens = []\n",
        "\n",
        "    for _ in range(max_target_len):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0:\n",
        "            break\n",
        "\n",
        "        sampled_word = fra_index_to_word.get(sampled_token_index, \"\")\n",
        "\n",
        "        if sampled_word == \"<end>\":\n",
        "            break\n",
        "\n",
        "        decoded_tokens.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]], dtype=\"int32\")\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mOI4BbF58ecp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_and_evaluate(\n",
        "    latent_dim,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    eval_samples=200,       # how many test samples to use for BLEU\n",
        "    max_decode_len=25       # max tokens to generate per sentence\n",
        "):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Training model with latent_dim = {latent_dim}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    t0 = time.time()\n",
        "    print(\"[1] Building model...\")\n",
        "\n",
        "    (\n",
        "        model,\n",
        "        encoder_inputs,\n",
        "        encoder_states,\n",
        "        decoder_inputs,\n",
        "        decoder_lstm,\n",
        "        decoder_dense,\n",
        "        decoder_embedding_layer,\n",
        "    ) = build_seq2seq_model(latent_dim=latent_dim)\n",
        "\n",
        "    print(f\"[1] Model built in {time.time() - t0:.2f} sec\")\n",
        "\n",
        "    print(\"\\n[2] Starting Training...\")\n",
        "    t1 = time.time()\n",
        "\n",
        "    history = model.fit(\n",
        "        [encoder_input_train, decoder_input_train],\n",
        "        decoder_target_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "\n",
        "    print(f\"[2] Training finished in {time.time() - t1:.2f} sec\")\n",
        "\n",
        "    print(\"\\n[3] Building inference models...\")\n",
        "    t2 = time.time()\n",
        "\n",
        "    encoder_model, decoder_model = build_inference_models(\n",
        "        encoder_inputs,\n",
        "        encoder_states,\n",
        "        decoder_inputs,\n",
        "        decoder_lstm,\n",
        "        decoder_dense,\n",
        "        decoder_embedding_layer,\n",
        "        latent_dim,\n",
        "    )\n",
        "\n",
        "    print(f\"[3] Inference models built in {time.time() - t2:.2f} sec\")\n",
        "\n",
        "    # ------------ BLEU EVALUATION (LIGHT) ------------\n",
        "    print(\"\\n[4] Starting BLEU evaluation on subset...\")\n",
        "    t3 = time.time()\n",
        "\n",
        "    references = []\n",
        "    candidates = []\n",
        "\n",
        "    total_test = encoder_input_test.shape[0]\n",
        "    num_test_samples = min(eval_samples, total_test)\n",
        "    print(f\"[4] Using {num_test_samples} / {total_test} test samples for BLEU\")\n",
        "\n",
        "    for i in range(num_test_samples):\n",
        "        if i % 50 == 0:\n",
        "            print(f\"  Decoding sample {i}/{num_test_samples} ...\")\n",
        "\n",
        "        input_seq = encoder_input_test[i : i + 1]\n",
        "\n",
        "        decoded_sentence = decode_sequence_greedy(\n",
        "            input_seq,\n",
        "            encoder_model,\n",
        "            decoder_model,\n",
        "            max_target_len=max_decode_len,   # <-- shorter decoding\n",
        "        )\n",
        "\n",
        "        ref_indices = decoder_target_test[i].squeeze()\n",
        "        ref_tokens = []\n",
        "        for idx in ref_indices:\n",
        "            if idx == 0:\n",
        "                continue\n",
        "            word = fra_index_to_word.get(idx, \"\")\n",
        "            if word == \"<end>\" or word == \"<start>\":\n",
        "                continue\n",
        "            ref_tokens.append(word)\n",
        "\n",
        "        references.append([ref_tokens])\n",
        "        candidates.append(decoded_sentence.split())\n",
        "\n",
        "    print(f\"[4] BLEU loop completed in {time.time() - t3:.2f} sec\")\n",
        "\n",
        "    bleu_score = corpus_bleu(references, candidates)\n",
        "    print(f\"\\nBLEU score for latent_dim = {latent_dim}: {bleu_score:.4f}\")\n",
        "\n",
        "    # ------------ QUALITATIVE EXAMPLES (FEW) ------------\n",
        "    print(\"\\n[5] Generating qualitative examples...\")\n",
        "    t4 = time.time()\n",
        "\n",
        "    for i in range(3):   # show only 3 instead of 5\n",
        "        print(f\"  Example {i+1}/3\")\n",
        "        idx = random.randint(0, total_test - 1)\n",
        "        input_seq = encoder_input_test[idx : idx + 1]\n",
        "        decoded_sentence = decode_sequence_greedy(\n",
        "            input_seq,\n",
        "            encoder_model,\n",
        "            decoder_model,\n",
        "            max_target_len=max_decode_len,\n",
        "        )\n",
        "\n",
        "        eng_original = decode_sequence_indices(\n",
        "            encoder_input_test[idx], eng_index_to_word\n",
        "        )\n",
        "        true_fra = decode_sequence_indices(\n",
        "            decoder_input_test[idx], fra_index_to_word\n",
        "        )\n",
        "\n",
        "        print(\"-\" * 40)\n",
        "        print(\"EN (input)   :\", eng_original)\n",
        "        print(\"FR (true)    :\", true_fra)\n",
        "        print(\"FR (decoded) :\", decoded_sentence)\n",
        "\n",
        "    print(f\"[5] Examples finished in {time.time() - t4:.2f} sec\")\n",
        "\n",
        "    total_time = time.time() - t0\n",
        "    print(\"\\n[ DONE ] Total time =\", round(total_time, 2), \"seconds\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return model, encoder_model, decoder_model, bleu_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWSBTjBreVeX",
        "outputId": "e640e7b9-81c5-49ef-cadb-b671d0d40559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Training model with latent_dim = 128\n",
            "============================================================\n",
            "[1] Building model...\n",
            "[1] Model built in 0.05 sec\n",
            "\n",
            "[2] Starting Training...\n",
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.0148 - loss: 7.9695 - val_accuracy: 0.0135 - val_loss: 6.1341\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0142 - loss: 6.0271 - val_accuracy: 0.0190 - val_loss: 6.0368\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.0183 - loss: 5.9223 - val_accuracy: 0.0202 - val_loss: 5.9870\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.0218 - loss: 5.8557 - val_accuracy: 0.0294 - val_loss: 5.8994\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 109ms/step - accuracy: 0.0318 - loss: 5.7370 - val_accuracy: 0.0343 - val_loss: 5.8182\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.0329 - loss: 5.6498 - val_accuracy: 0.0357 - val_loss: 5.7529\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 0.0339 - loss: 5.5778 - val_accuracy: 0.0365 - val_loss: 5.6943\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0345 - loss: 5.5170 - val_accuracy: 0.0373 - val_loss: 5.6395\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0353 - loss: 5.4528 - val_accuracy: 0.0382 - val_loss: 5.5707\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0361 - loss: 5.3750 - val_accuracy: 0.0391 - val_loss: 5.4935\n",
            "[2] Training finished in 107.91 sec\n",
            "\n",
            "[3] Building inference models...\n",
            "[3] Inference models built in 0.01 sec\n",
            "\n",
            "[4] Starting BLEU evaluation on subset...\n",
            "[4] Using 200 / 2000 test samples for BLEU\n",
            "  Decoding sample 0/200 ...\n",
            "  Decoding sample 50/200 ...\n",
            "  Decoding sample 100/200 ...\n",
            "  Decoding sample 150/200 ...\n",
            "[4] BLEU loop completed in 352.72 sec\n",
            "\n",
            "BLEU score for latent_dim = 128: 0.0000\n",
            "\n",
            "[5] Generating qualitative examples...\n",
            "  Example 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "EN (input)   : i don t think that i want to answer any more of your questions right now .\n",
            "FR (true)    : <start> je ne pense pas avoir envie de repondre a plus de vos questions pour le moment .\n",
            "FR (decoded) : je ne ne que je ne ne que je ne ne que je ne ne que je ne ne a de .\n",
            "  Example 2/3\n",
            "----------------------------------------\n",
            "EN (input)   : don t get so irritated . rushing things will cost you more time in the end .\n",
            "FR (true)    : <start> ne t agace pas comme cela . se precipiter te fera perdre du temps en fin de compte .\n",
            "FR (decoded) : je ne ne que je ne ne que je ne ne que je ne ne a de a de .\n",
            "  Example 3/3\n",
            "----------------------------------------\n",
            "EN (input)   : a more experienced lawyer would have dealt with the case in a different way .\n",
            "FR (true)    : <start> un avocat plus experimente aurait traite l affaire differemment .\n",
            "FR (decoded) : je ne ne a de a de a de a de a de a de a de a de a de a .\n",
            "[5] Examples finished in 6.28 sec\n",
            "\n",
            "[ DONE ] Total time = 466.98 seconds\n",
            "============================================================\n",
            "BLEU (128 units): 3.7803297262219836e-79\n"
          ]
        }
      ],
      "source": [
        "model_128, enc_128, dec_128, bleu_128 = train_and_evaluate(\n",
        "    latent_dim=128,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    eval_samples=200,     # subset of test set\n",
        "    max_decode_len=25     # cap decoded length\n",
        ")\n",
        "\n",
        "print(\"BLEU (128 units):\", bleu_128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHF-_wLeee5N",
        "outputId": "36012120-dc7b-4440-fc89-e64a112afccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Training model with latent_dim = 128\n",
            "============================================================\n",
            "[1] Building model...\n",
            "[1] Model built in 0.06 sec\n",
            "\n",
            "[2] Starting Training...\n",
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.0142 - loss: 7.9307 - val_accuracy: 0.0135 - val_loss: 6.1548\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 109ms/step - accuracy: 0.0136 - loss: 6.0599 - val_accuracy: 0.0135 - val_loss: 6.0998\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.0141 - loss: 5.9920 - val_accuracy: 0.0189 - val_loss: 6.0493\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0195 - loss: 5.9099 - val_accuracy: 0.0334 - val_loss: 5.9080\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.0320 - loss: 5.7508 - val_accuracy: 0.0339 - val_loss: 5.8144\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.0329 - loss: 5.6514 - val_accuracy: 0.0354 - val_loss: 5.7374\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0339 - loss: 5.5710 - val_accuracy: 0.0358 - val_loss: 5.6702\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0346 - loss: 5.4962 - val_accuracy: 0.0369 - val_loss: 5.5977\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0353 - loss: 5.4156 - val_accuracy: 0.0373 - val_loss: 5.5317\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.0361 - loss: 5.3442 - val_accuracy: 0.0381 - val_loss: 5.4772\n",
            "[2] Training finished in 107.76 sec\n",
            "\n",
            "[3] Building inference models...\n",
            "[3] Inference models built in 0.01 sec\n",
            "\n",
            "[4] Starting BLEU evaluation on subset...\n",
            "[4] Using 200 / 2000 test samples for BLEU\n",
            "  Decoding sample 0/200 ...\n",
            "  Decoding sample 50/200 ...\n",
            "  Decoding sample 100/200 ...\n",
            "  Decoding sample 150/200 ...\n",
            "[4] BLEU loop completed in 311.26 sec\n",
            "\n",
            "BLEU score for latent_dim = 128: 0.0000\n",
            "\n",
            "[5] Generating qualitative examples...\n",
            "  Example 1/3\n",
            "----------------------------------------\n",
            "EN (input)   : it was only much later that i came to understand the importance of child education .\n",
            "FR (true)    : <start> ce n est que bien plus tard que j ai compris l importance de l education des enfants .\n",
            "FR (decoded) : je ne ai que je ne ne a que il ne ne l l l l l .\n",
            "  Example 2/3\n",
            "----------------------------------------\n",
            "EN (input)   : you might think i m too old for you , but i don t think you re too young for me .\n",
            "FR (true)    : <start> tu penses peut etre que je suis trop vieux pour toi , mais je ne pense pas que tu es trop jeune pour moi .\n",
            "FR (decoded) : je ne ai que je ne ne a que il ne ne a a que il ne ne l l l l l l .\n",
            "  Example 3/3\n",
            "----------------------------------------\n",
            "EN (input)   : companies with diversified holdings tend to weather economics shocks better .\n",
            "FR (true)    : <start> les societes disposant d actifs diversifies tendent a mieux encaisser les chocs economiques .\n",
            "FR (decoded) : je ne ai a que il ne l l l l l .\n",
            "[5] Examples finished in 4.47 sec\n",
            "\n",
            "[ DONE ] Total time = 423.58 seconds\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Training model with latent_dim = 256\n",
            "============================================================\n",
            "[1] Building model...\n",
            "[1] Model built in 0.10 sec\n",
            "\n",
            "[2] Starting Training...\n",
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - accuracy: 0.0159 - loss: 7.5769 - val_accuracy: 0.0217 - val_loss: 6.0174\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 121ms/step - accuracy: 0.0206 - loss: 5.8959 - val_accuracy: 0.0246 - val_loss: 5.9355\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.0242 - loss: 5.7994 - val_accuracy: 0.0339 - val_loss: 5.8459\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.0325 - loss: 5.6730 - val_accuracy: 0.0345 - val_loss: 5.7614\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.0334 - loss: 5.5738 - val_accuracy: 0.0360 - val_loss: 5.6726\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.0348 - loss: 5.4725 - val_accuracy: 0.0380 - val_loss: 5.5679\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.0368 - loss: 5.3567 - val_accuracy: 0.0402 - val_loss: 5.4750\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.0388 - loss: 5.2549 - val_accuracy: 0.0418 - val_loss: 5.3904\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.0404 - loss: 5.1589 - val_accuracy: 0.0417 - val_loss: 5.3442\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.0419 - loss: 5.0573 - val_accuracy: 0.0455 - val_loss: 5.2280\n",
            "[2] Training finished in 126.43 sec\n",
            "\n",
            "[3] Building inference models...\n",
            "[3] Inference models built in 0.01 sec\n",
            "\n",
            "[4] Starting BLEU evaluation on subset...\n",
            "[4] Using 200 / 2000 test samples for BLEU\n",
            "  Decoding sample 0/200 ...\n",
            "  Decoding sample 50/200 ...\n",
            "  Decoding sample 100/200 ...\n",
            "  Decoding sample 150/200 ...\n",
            "[4] BLEU loop completed in 246.09 sec\n",
            "\n",
            "BLEU score for latent_dim = 256: 0.0000\n",
            "\n",
            "[5] Generating qualitative examples...\n",
            "  Example 1/3\n",
            "----------------------------------------\n",
            "EN (input)   : when i got my driver s license renewed , i had to decide if i wanted to be an organ donor .\n",
            "FR (true)    : <start> quand j ai fait renouvele mon permis de conduire , j ai du decider si je voulais etre donneur d organe .\n",
            "FR (decoded) : je ne ai pas pas que je ne ai pas pas que je ne ai pas pas .\n",
            "  Example 2/3\n",
            "----------------------------------------\n",
            "EN (input)   : tom and mary have been divorced for over three years . really ? i had no idea .\n",
            "FR (true)    : <start> tom et marie sont divorces depuis plus de trois ans . vraiment ? je n en avais aucune idee .\n",
            "FR (decoded) : tom est que vous ne ai pas pas , je ne ai pas pas .\n",
            "  Example 3/3\n",
            "----------------------------------------\n",
            "EN (input)   : i can help you chart the course , but you have to make the journey on your own .\n",
            "FR (true)    : <start> je peux vous aider a tracer la carte mais vous devez accomplir le periple par vous meme .\n",
            "FR (decoded) : je ne ai pas pas que je ne ai pas pas que je ne ai pas pas .\n",
            "[5] Examples finished in 4.33 sec\n",
            "\n",
            "[ DONE ] Total time = 376.98 seconds\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Training model with latent_dim = 512\n",
            "============================================================\n",
            "[1] Building model...\n",
            "[1] Model built in 0.46 sec\n",
            "\n",
            "[2] Starting Training...\n",
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.0159 - loss: 7.3389 - val_accuracy: 0.0238 - val_loss: 5.9551\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.0228 - loss: 5.8339 - val_accuracy: 0.0340 - val_loss: 5.8407\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.0322 - loss: 5.6606 - val_accuracy: 0.0351 - val_loss: 5.7458\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.0340 - loss: 5.5379 - val_accuracy: 0.0378 - val_loss: 5.6091\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - accuracy: 0.0366 - loss: 5.3756 - val_accuracy: 0.0392 - val_loss: 5.4874\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - accuracy: 0.0395 - loss: 5.1962 - val_accuracy: 0.0438 - val_loss: 5.3153\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.0419 - loss: 5.0442 - val_accuracy: 0.0438 - val_loss: 5.2964\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - accuracy: 0.0433 - loss: 4.9266 - val_accuracy: 0.0464 - val_loss: 5.1769\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - accuracy: 0.0446 - loss: 4.8163 - val_accuracy: 0.0477 - val_loss: 5.1107\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.0462 - loss: 4.7107 - val_accuracy: 0.0493 - val_loss: 5.0306\n",
            "[2] Training finished in 173.77 sec\n",
            "\n",
            "[3] Building inference models...\n",
            "[3] Inference models built in 0.01 sec\n",
            "\n",
            "[4] Starting BLEU evaluation on subset...\n",
            "[4] Using 200 / 2000 test samples for BLEU\n",
            "  Decoding sample 0/200 ...\n",
            "  Decoding sample 50/200 ...\n",
            "  Decoding sample 100/200 ...\n",
            "  Decoding sample 150/200 ...\n",
            "[4] BLEU loop completed in 280.31 sec\n",
            "\n",
            "BLEU score for latent_dim = 512: 0.0000\n",
            "\n",
            "[5] Generating qualitative examples...\n",
            "  Example 1/3\n",
            "----------------------------------------\n",
            "EN (input)   : please boil the eggs just a little so that even the whites are not quite hard .\n",
            "FR (true)    : <start> veuillez faire bouillir juste un peu les ufs , de maniere a ce que meme les blancs ne soient pas tout a fait durs .\n",
            "FR (decoded) : tom est a la maison de la maison , mais je ne ai pas pas .\n",
            "  Example 2/3\n",
            "----------------------------------------\n",
            "EN (input)   : the judge asked the defendant if he knew the difference between telling the truth and telling a lie .\n",
            "FR (true)    : <start> le juge a demande a l accuse s il connaissait la difference entre dire la verite et dire un mensonge .\n",
            "FR (decoded) : il est a la maison de l maison , mais il est a la maison .\n",
            "  Example 3/3\n",
            "----------------------------------------\n",
            "EN (input)   : i thought that we had found the perfect hiding place , but the police found us .\n",
            "FR (true)    : <start> je pensais que nous avions trouve la cachette parfaite mais la police nous a trouves .\n",
            "FR (decoded) : je ne ai pas pas que je ne ai pas pas que je ne ai pas pas .\n",
            "[5] Examples finished in 4.87 sec\n",
            "\n",
            "[ DONE ] Total time = 459.45 seconds\n",
            "============================================================\n",
            "\n",
            "Summary of BLEU scores:\n",
            "latent_dim = 128: BLEU = 0.0000\n",
            "latent_dim = 256: BLEU = 0.0000\n",
            "latent_dim = 512: BLEU = 0.0000\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "for latent_dim in [128, 256, 512]:\n",
        "    model, enc, dec, bleu = train_and_evaluate(\n",
        "        latent_dim=latent_dim,\n",
        "        epochs=10,\n",
        "        batch_size=64,\n",
        "        eval_samples=200,\n",
        "        max_decode_len=25,\n",
        "    )\n",
        "    results[latent_dim] = bleu\n",
        "\n",
        "print(\"\\nSummary of BLEU scores:\")\n",
        "for d, b in results.items():\n",
        "    print(f\"latent_dim = {d}: BLEU = {b:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Kh452ol2-W",
        "outputId": "1ccd56cd-efcc-478f-b3d5-2c95529442f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "latent_dim: 128     BLEU: 4.1761439764183904e-79\n",
            "latent_dim: 256     BLEU: 4.6017578836795294e-79\n",
            "latent_dim: 512     BLEU: 5.827555451330451e-79\n"
          ]
        }
      ],
      "source": [
        "for i,j in results.items():\n",
        "  print('latent_dim:',i,' '*3,'BLEU:',j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08RiHspgmx6h"
      },
      "source": [
        "Discuss how sequence length affect performance?\n",
        "\n",
        "Sequence length has a strong negative effect on Seq2Seq performance. Longer sentences make it harder for the encoder to compress all information into a fixed-length vector, and the decoder struggles to generate long, coherent outputs. Errors compound over time, and BLEU-4 severely penalizes mismatches on long sequences. As a result, our model produces repetitive or generic patterns and ends up with near-zero BLEU scores across all hidden sizes. Increasing the LSTM size (128 → 256 → 512) provides minor improvement, but does not overcome the limitations imposed by long input and output sequences in a vanilla Seq2Seq architecture without attention."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
